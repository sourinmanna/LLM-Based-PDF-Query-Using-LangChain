{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "814ab56a",
   "metadata": {},
   "source": [
    "### A question-answering demo using Astra DB and LangChain, powered by Vector Search"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7d57e28b",
   "metadata": {},
   "source": [
    "#### Pre-requisites:\n",
    "\n",
    "**_Serverless Cassandra with Vector Search_** database on [Astra DB](https://astra.datastax.com) to run this demo. As outlined in more detail [here](https://docs.datastax.com/en/astra-serverless/docs/vector-search/quickstart.html#_prepare_for_using_your_vector_database), the DB Token with role _Database Administrator_ and copy Database ID: these connection parameters are needed momentarily.\n",
    "\n",
    "#### What you will do:\n",
    "\n",
    "- Setup: import dependencies, provide secrets, create the LangChain vector store;\n",
    "- Run a Question-Answering loop retrieving the relevant headlines and having an LLM construct the answer."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8b857442",
   "metadata": {},
   "source": [
    "Import the packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "68f0f0d5",
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mRunning cells with 'pdf_query_venv (3.10.8) (Python 3.10.8)' requires the ipykernel package.\n",
      "\u001b[1;31mInstall 'ipykernel' into the Python environment. \n",
      "\u001b[1;31mCommand: 'c:/Users/HP/OneDrive/Documents/GitHub/LLM-Based-PDF-Query-31-08-2025/pdf_query_venv/Scripts/python.exe -m pip install ipykernel -U --force-reinstall'"
     ]
    }
   ],
   "source": [
    "# LangChain components to use\n",
    "from langchain.vectorstores.cassandra import Cassandra\n",
    "from langchain.indexes.vectorstore import VectorStoreIndexWrapper\n",
    "from langchain.llms import OpenAI\n",
    "from langchain.embeddings import OpenAIEmbeddings\n",
    "from PyPDF2 import PdfReader\n",
    "from langchain_community.llms import Ollama\n",
    "from langchain.embeddings import HuggingFaceEmbeddings\n",
    "\n",
    "# Support for dataset retrieval with Hugging Face\n",
    "from datasets import load_dataset\n",
    "\n",
    "# With CassIO, the engine powering the Astra DB integration in LangChain,\n",
    "# you will also initialize the DB connection:\n",
    "import cassio"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8cd74949",
   "metadata": {},
   "source": [
    "Key Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "89bc1752",
   "metadata": {},
   "outputs": [],
   "source": [
    "ASTRA_DB_APPLICATION_TOKEN = \"AstraCS:DTTQOMiQKzsmpGQHvyaEoKth:e397dd9ad202ab01c589ca0212ed7b1e7de0f76bddeef0787423406734d9624f\" # enter the \"AstraCS:...\" string found in in your Token JSON file\n",
    "ASTRA_DB_ID = \"3b67d6de-ff55-4e11-ad7b-d4f3762e2ad7\" # enter your Database ID"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9816b317",
   "metadata": {},
   "source": [
    "Input pdf file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "77375899",
   "metadata": {},
   "outputs": [],
   "source": [
    "# provide the path of  pdf file/files.\n",
    "pdfreader = PdfReader('data\\\\budget_speech.pdf')\n",
    "print(pdfreader)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2732a7db",
   "metadata": {},
   "source": [
    "Extract all text from PDF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f2d3745b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# read text from pdf\n",
    "raw_text = ''\n",
    "for i, page in enumerate(pdfreader.pages):\n",
    "    content = page.extract_text()\n",
    "    if content:\n",
    "        raw_text += content\n",
    "print(raw_text)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3f540bf9",
   "metadata": {},
   "source": [
    "Initialize the connection to your database:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f78bab6b",
   "metadata": {},
   "outputs": [],
   "source": [
    "cassio.init(token=ASTRA_DB_APPLICATION_TOKEN, database_id=ASTRA_DB_ID)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1245cc95",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Local LLM via Ollama\n",
    "llm = Ollama(model=\"llama3.2\")\n",
    "\n",
    "# Local embeddings\n",
    "embedding = HuggingFaceEmbeddings(model_name=\"sentence-transformers/all-MiniLM-L6-v2\")\n",
    "embedding"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0ba348ed",
   "metadata": {},
   "source": [
    "Create your LangChain vector store ... backed by Astra DB!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "07f4961f",
   "metadata": {},
   "outputs": [],
   "source": [
    "astra_vector_store = Cassandra(\n",
    "    embedding=embedding,\n",
    "    table_name=\"pdf_qa_query_db\",\n",
    "    session=None,\n",
    "    keyspace=None,\n",
    ")\n",
    "astra_vector_store"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aafb86a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.text_splitter import CharacterTextSplitter\n",
    "# We need to split the text using Character Text Split such that it sshould not increse token size\n",
    "text_splitter = CharacterTextSplitter(\n",
    "    separator = \"\\n\",\n",
    "    chunk_size = 800,\n",
    "    chunk_overlap  = 200,\n",
    "    length_function = len,\n",
    ")\n",
    "texts = text_splitter.split_text(raw_text)\n",
    "len(texts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "40c8d4c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "texts[:5]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fadd0810",
   "metadata": {},
   "source": [
    "Load the dataset into the vector store"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10123631",
   "metadata": {},
   "outputs": [],
   "source": [
    "astra_vector_store.add_texts(texts)\n",
    "\n",
    "print(\"Inserted %i headlines.\" % len(texts))\n",
    "\n",
    "astra_vector_index = VectorStoreIndexWrapper(vectorstore=astra_vector_store)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d9c435f8",
   "metadata": {},
   "source": [
    "### Run the QA cycle\n",
    "\n",
    "Simply run the cells and ask a question -- or `quit` to stop. (you can also stop execution with the \"â–ª\" button on the top toolbar)\n",
    "\n",
    "Here are some suggested questions:\n",
    "- _What is the current GDP?_\n",
    "- _How much the agriculture target will be increased to and what the focus will be_\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8cde5642",
   "metadata": {},
   "outputs": [],
   "source": [
    "first_question = True\n",
    "while True:\n",
    "    if first_question:\n",
    "        query_text = input(\"\\nEnter your question (or type 'quit' to exit): \").strip()\n",
    "    else:\n",
    "        query_text = input(\"\\nWhat's your next question (or type 'quit' to exit): \").strip()\n",
    "\n",
    "    if query_text.lower() == \"quit\":\n",
    "        break\n",
    "\n",
    "    if query_text == \"\":\n",
    "        continue\n",
    "\n",
    "    first_question = False\n",
    "\n",
    "    print(\"\\nQUESTION: \\\"%s\\\"\" % query_text)\n",
    "    answer = astra_vector_index.query(query_text, llm=llm).strip()\n",
    "    print(\"ANSWER: \\\"%s\\\"\\n\" % answer)\n",
    "\n",
    "    print(\"FIRST DOCUMENTS BY RELEVANCE:\")\n",
    "    for doc, score in astra_vector_store.similarity_search_with_score(query_text, k=4):\n",
    "        print(\"    [%0.4f] \\\"%s ...\\\"\" % (score, doc.page_content[:84]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb8caa89",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pdf_query_venv (3.10.8)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
